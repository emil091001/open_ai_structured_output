{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilschneiderlorentzen/UNI/6sm/project/open_ai_structured_output/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from structure import Structure\n",
    "import json\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "from prompts import *\n",
    "from pydantic import BaseModel\n",
    "from transformers import GPT2TokenizerFast\n",
    "from copy import deepcopy\n",
    "from prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-10-21\",\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('Xenova/gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestStructure(BaseModel):\n",
    "    original_language: str\n",
    "    translated_language: str\n",
    "    original_text: str\n",
    "    translated_text: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = open(\"../data/pdf/BAU-EPD_Knauf-2025-21-ecoinvent-Fireboard_12,5.txt\", \"r\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Translate to danish\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is Emil\"}\n",
    "    ],\n",
    "    response_format=TestStructure,\n",
    "    temperature=0.0,\n",
    "    logprobs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(completion.choices[0].logprobs.to_dict(), open(\"../data/logprobs/BAU-EPD_Knauf-2025-21-ecoinvent-Fireboard_12,5.json\", \"w\"), indent=4)\n",
    "json.dump(json.loads(completion.choices[0].message.content), open(\"../data/test_output/BAU-EPD_Knauf-2025-21-ecoinvent-Fireboard_12,5.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"original_language\":\"English\",\"translated_language\":\"Danish\",\"original_text\":\"My name is Emil\",\"translated_text\":\"Mit navn er Emil\"}\n"
     ]
    }
   ],
   "source": [
    "content = completion.choices[0].message.content\n",
    "print(content)\n",
    "# dud = json.loads(content)\n",
    "\n",
    "howar\n",
    "\n",
    "# tokens = tokenizer(json.dumps(dud, separators=(\",\", \":\")))\n",
    "# for token in tokens['input_ids']:\n",
    "#     print(tokenizer.decode([token]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\" \t\t 0.0\n",
      "original \t\t 0.0\n",
      "_language \t\t -7.89631e-07\n",
      "\":\" \t\t 0.0\n",
      "English \t\t -0.000181849\n",
      "\",\" \t\t 0.0\n",
      "translated \t\t 0.0\n",
      "_language \t\t 0.0\n",
      "\":\" \t\t 0.0\n",
      "D \t\t -1.147242e-06\n",
      "anish \t\t 0.0\n",
      "\",\" \t\t 0.0\n",
      "original \t\t 0.0\n",
      "_text \t\t 0.0\n",
      "\":\" \t\t 0.0\n",
      "My \t\t 0.0\n",
      " name \t\t 0.0\n",
      " is \t\t 0.0\n",
      " Emil \t\t 0.0\n",
      "\",\" \t\t -0.0019287518\n",
      "translated \t\t 0.0\n",
      "_text \t\t 0.0\n",
      "\":\" \t\t 0.0\n",
      "Mit \t\t -0.004632688\n",
      " navn \t\t -2.577686e-06\n",
      " er \t\t -4.3202e-07\n",
      " Emil \t\t 0.0\n",
      "\"} \t\t -1.0206721e-05\n"
     ]
    }
   ],
   "source": [
    "for hej in completion.choices[0].logprobs.content:\n",
    "    print(hej.token, \"\\t\\t\", hej.logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"token\": \"{\\\"\",\n",
      "      \"bytes\": [\n",
      "        123,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"original\",\n",
      "      \"bytes\": [\n",
      "        111,\n",
      "        114,\n",
      "        105,\n",
      "        103,\n",
      "        105,\n",
      "        110,\n",
      "        97,\n",
      "        108\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"_language\",\n",
      "      \"bytes\": [\n",
      "        95,\n",
      "        108,\n",
      "        97,\n",
      "        110,\n",
      "        103,\n",
      "        117,\n",
      "        97,\n",
      "        103,\n",
      "        101\n",
      "      ],\n",
      "      \"logprob\": -6.704273e-7,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\":\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        58,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"English\",\n",
      "      \"bytes\": [\n",
      "        69,\n",
      "        110,\n",
      "        103,\n",
      "        108,\n",
      "        105,\n",
      "        115,\n",
      "        104\n",
      "      ],\n",
      "      \"logprob\": -0.00016825978,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\",\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        44,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"translated\",\n",
      "      \"bytes\": [\n",
      "        116,\n",
      "        114,\n",
      "        97,\n",
      "        110,\n",
      "        115,\n",
      "        108,\n",
      "        97,\n",
      "        116,\n",
      "        101,\n",
      "        100\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"_language\",\n",
      "      \"bytes\": [\n",
      "        95,\n",
      "        108,\n",
      "        97,\n",
      "        110,\n",
      "        103,\n",
      "        117,\n",
      "        97,\n",
      "        103,\n",
      "        101\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\":\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        58,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"D\",\n",
      "      \"bytes\": [\n",
      "        68\n",
      "      ],\n",
      "      \"logprob\": -4.3202e-7,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"anish\",\n",
      "      \"bytes\": [\n",
      "        97,\n",
      "        110,\n",
      "        105,\n",
      "        115,\n",
      "        104\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\",\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        44,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"original\",\n",
      "      \"bytes\": [\n",
      "        111,\n",
      "        114,\n",
      "        105,\n",
      "        103,\n",
      "        105,\n",
      "        110,\n",
      "        97,\n",
      "        108\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"_text\",\n",
      "      \"bytes\": [\n",
      "        95,\n",
      "        116,\n",
      "        101,\n",
      "        120,\n",
      "        116\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\":\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        58,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"My\",\n",
      "      \"bytes\": [\n",
      "        77,\n",
      "        121\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" name\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        110,\n",
      "        97,\n",
      "        109,\n",
      "        101\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" is\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        105,\n",
      "        115\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" Emil\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        69,\n",
      "        109,\n",
      "        105,\n",
      "        108\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\",\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        44,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": -0.0028048719,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"translated\",\n",
      "      \"bytes\": [\n",
      "        116,\n",
      "        114,\n",
      "        97,\n",
      "        110,\n",
      "        115,\n",
      "        108,\n",
      "        97,\n",
      "        116,\n",
      "        101,\n",
      "        100\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"_text\",\n",
      "      \"bytes\": [\n",
      "        95,\n",
      "        116,\n",
      "        101,\n",
      "        120,\n",
      "        116\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\":\\\"\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        58,\n",
      "        34\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"Mit\",\n",
      "      \"bytes\": [\n",
      "        77,\n",
      "        105,\n",
      "        116\n",
      "      ],\n",
      "      \"logprob\": -0.005941952,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" navn\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        110,\n",
      "        97,\n",
      "        118,\n",
      "        110\n",
      "      ],\n",
      "      \"logprob\": -2.9352968e-6,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" er\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        101,\n",
      "        114\n",
      "      ],\n",
      "      \"logprob\": -4.3202e-7,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \" Emil\",\n",
      "      \"bytes\": [\n",
      "        32,\n",
      "        69,\n",
      "        109,\n",
      "        105,\n",
      "        108\n",
      "      ],\n",
      "      \"logprob\": 0.0,\n",
      "      \"top_logprobs\": []\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"\\\"}\",\n",
      "      \"bytes\": [\n",
      "        34,\n",
      "        125\n",
      "      ],\n",
      "      \"logprob\": -0.000018193366,\n",
      "      \"top_logprobs\": []\n",
      "    }\n",
      "  ],\n",
      "  \"refusal\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].logprobs.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = json.loads(open(\"../data/nice_epds/BAU-EPD-Mischek-2025-4-ecoinvent-Massivwand-5kg.json\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'environmental_impact': [{'parameter': 'GWP-total', 'values': ['###']}]}\n",
      "{'environmental_impact': [{'parameter': 'GWP-total', 'values': [{'value': '7,28E+01', 'module': 'A1-A3', 'scenario': None}, '###']}]}\n"
     ]
    }
   ],
   "source": [
    "tables = [\n",
    "        'environmental_impact',\n",
    "        'additional_environmental_impact',\n",
    "        'resource_use',\n",
    "        'end_of_life_waste',\n",
    "        'end_of_life_flow']\n",
    "\n",
    "columns = [\"A1\",\t\"A2\",\t\"A3\",\t\"A1-A3\", \"A4\",\t\"A5\",\t\"B1\",\t\"B2\",\t\"B3\",\t\"B4\",\t\"B5\",\t\"B6\",\t\"B7\",\t\"C1\",\t\"C2\",\t\"C3\",\t\"C4\",\t\"D\"]\n",
    "\n",
    "filtered_output_start = {}\n",
    "filtered_output_end = {}\n",
    "\n",
    "MARKER = \"###\"\n",
    "MARKER_TOKEN = tokenizer(MARKER)['input_ids'][0]\n",
    "\n",
    "for table in tables:\n",
    "    filtered_output_start[table] = []\n",
    "    filtered_output_end[table] = []\n",
    "    rows = target[table]\n",
    "    \n",
    "    for row in rows:\n",
    "        filtered_row = {}\n",
    "        filtered_row['parameter'] = row['parameter']\n",
    "        filtered_row['values'] = []\n",
    "        for value in row['values']:\n",
    "            filtered_row['values'].append(MARKER)\n",
    "            filtered_output_start[table].append(deepcopy(filtered_row))\n",
    "            filtered_row['values'].pop()\n",
    "            filtered_row['values'].append(value)\n",
    "            filtered_row['values'].append(MARKER)\n",
    "            filtered_output_end[table].append(deepcopy(filtered_row))\n",
    "            filtered_row['values'].pop()\n",
    "            \n",
    "            break\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(filtered_output_start)\n",
    "print(filtered_output_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string = json.dumps(filtered_output_start, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_string_start = json.dumps(filtered_output_start, separators=(',', ':'))\n",
    "filtered_string_end = json.dumps(filtered_output_end, separators=(',', ':'))\n",
    "\n",
    "start_tokens = tokenizer(filtered_string_start)['input_ids']\n",
    "end_tokens = tokenizer(filtered_string_end)['input_ids']\n",
    "\n",
    "start_index = start_tokens.index(MARKER_TOKEN)\n",
    "end_index = end_tokens.index(MARKER_TOKEN)\n",
    "\n",
    "\n",
    "start_tokens_prime = start_tokens[:start_index]\n",
    "end_tokens_prime = end_tokens[:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"environmental_impact\":[{\"parameter\":\"GWP-total\",\"values\":[\"###\"]}]}\n",
      "{\"value\":\"7,28E+01\",\"module\":\"A1-A3\",\"scenario\":null\n"
     ]
    }
   ],
   "source": [
    "#filtered_string_start[:filtered_string_start.index(MARKER_TOKEN)]\n",
    "print(tokenizer.decode(start_tokens))\n",
    "print(tokenizer.decode(end_tokens[len(start_tokens_prime):len(end_tokens_prime) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "-1000 < -math.inf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
